# 카프카 커맨드 라인 소개

## 카프카 커맨드 라인 툴

카프카에서 제공하는 카프카 커맨드 라인 툴(command-line too)들은 카프카를 운영할 때 가장 많이 접 하는 도구다.

커맨드 라인 툴을 통해 카프카 브로커 운영에 필요한 다양한 명령을 내릴 수 있다.

카프카 클 라이언트 애플리케이션을 운영할 때는 카프카 클러스터와 연동하여 데이터를 주고받는 것도 중요하지만 토픽이나 파티션 개수 변경과 같은 명령을 실행해야 하는 경우도 자주 발생한다.

그렇기 때문에 카프카 커 맨드 라인툴과 각 툴별 옵션에 대해 알고있어야 한다.

카프카의 명령어들은 관련 애플리케이션을 개발할 때 그리고 클러스터를 운영할 때 자주 쓰인다.

너무 긴 명령어라 입력하기 부담스러울 수도 있겠지만 손에 익으면 실무에서 편하게 사용할 수 있다.

커맨드 라인 툴을 통해 토픽 관련 명령을 실행할 때 필수 옵션과 선택 옵션이 있다.

선택 옵션은 지정하지 않을시 브로커에 설정된 기본 설정값 또는 커맨드 라인 둘의 기본값으로 대체되어 설정된다.

그러므로 커맨드 라인 툴을 사용하기 전에 현재 브로커에 옵션이 어떻게 설정되어 있는지 확인한 후에 사용하면 커맨 드라인 툴 사용시 실수할 확률이 줄어든다.

=> 프로듀서 몇개, 컨슈머 몇개 등 다 확인 하려면 필요. 다 확인하고 해야 실수 확률 줄어든다.

# 로컬 카프카 설치 및 카프카 CLI 실습

## 예제 코드 다운로드

```java
git clone <https://github.com/bjpublic/apache-kafka-with-java.git>
```

## 로컬 카프카 설치 및 실행

1. 카프카 바이너리 파일 다운로드

- https://kafka.apache.org/downloads
- Binary downloads: kafka_2.12-2.5.0.tgz

1. 카프카 바이너리 압축 해제
2. 주키퍼 실행
3. 카프카 바이너리 실행

## 카프카 바이너리 압축 해제

```java
$ ls ~/Downloads/kafka_2.12-2.5.0

$ mkdir data
     
//broker.id = (0부터 시작1 2 3...)
num.network.threads=3
num.io.threads=8 
log.dirs=/home/ekdrms/kafka_2.12-2.5.0/data 
num.partitions=3
listeners=PLAINTEXT://localhost:9092
advertised. listeners=PLAINTEXT://localhost: 9092
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper .connect=localhost: 2181
zookeeper. connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
```

## 주키퍼 실행

```java
$ cat config/zookeeper.properties
dataDir=/tmp/zookeeper 
clientPort=2181
maxClientCnxns=0
admin.enableServer=false

$ bin/zookeeper-server-start. sh config/zookeeper .properties
```

## 카프카 브로커 실행

```java
$ bin/kafka-server-start.sh config/server.properties

[2021-11-16 23:37:48,785] INFO Registered kafka:type=kafka.Log4jController
MBean (kafka.utils.Log4jControllerRegistration$)

[2021-11-16 23:37:49,832] INFO Kafka version: 2.5.0 
(org. apache.kafka.common.utils. AppInfoParser)
[2021-11-16 23:37:49, 832] INFO Kafka startTimeMs: 1637073469830
(org. apache.kafka.common.utils. AppInfoParser)
[2021-11-16 23:37:49,833] INFO [KafkaServer id=0] started 
(kafka.server .KafkaServer)
```

## 카프카 정상 실행 여부 확인

```java
$ bin/kafka-broker-api-versions.sh --bootstrap-server localhost: 9092
192.168.0.11:9092 (id: 0 rack: null) -> (
	Produce(0): 0 to 8 [usable: 8],

	DeleteGroups (42): 0 to 2 [usable: 2], 
	ElectLeaders (43): 0 to 2 [usable: 21, 
	OffsetDelete (47): 0 usable: 0]
)

$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
```

## 테스트 편의를 위한 hosts 설정

```java
$ sudo vi /etc/hosts
Password:

127.0.0.1 localhost
255.255.255.255 broadcasthost
::1 localhost

127.0.0.1 my-kafka
    //alias
```

# [kafka-topics.sh](http://kafka-topics.sh)

## [kafka-topics.sh](http://kafka-topics.sh)

hello.kafka 토픽처럼 카프카 클러스터 정보와 토픽 이름만으로 토픽을 생성할 수 있었다.

클러스터 정보와 토픽 이름은 토픽을 만들기 위한 필수 값이다.

이렇게 만들어진 토픽은  파티션 개수, 복제 개수 등과 같이 다양한 옵션이 포함되어 있지만 모두 브로커에 설정된 기본값으로 생성되었다.

```java
$ bin/kafka-topics.sh --create \\
	--bootstrap-server my-kafka: 9092 \\
	--topic hello.kafka
Created topic hello.kafka.

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic hello.kafka \\
	--describe

Topic: hello.kafka PartitionCount: 1 ReplicationFactor: 1 Configs:
segment.bytes=1073741824
	Topic: hello.kafka Partition: 0 Leader: 0 Replicas: 0 Isr: 0
```

파티션 개수, 복제 개수, 토픽 데이터 유지 기간 옵션들을 지정하여 토픽을 생성하고 싶다면 다음과 같이 명령을 실행하면 된다.

생성된 토픽들의 이름을 조회하려면 --list 옵션을 사용한다

```java
$ bin/kafka-topics.sh --create \\
	--bootstrap-server my-kafka: 9092 \\
	--partitions 10 \\
	--replication-factor 1 \\
	--topic hello.kafka2 \\
	--config retention.ms=172800000

Created topic hello.kafka2.

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list 
hello.kafka hello.kafka2
```

파티션 개수를 늘리기 위해서 --alter 옵션을 사용하면 된다.

```java
$ bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --topic test
Created topic test

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic test --describe

Topic: test PartitionCount: 3 ReplicationFactor: 1 Configs:
segment.bytes=1073741824

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic test \\
	--alter --partitions 4

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic test --describe

Topic: test PartitionCount: 4 ReplicationFactor: 1 Configs:
segment.bytes=1073741824
```

파티션 개수를 늘릴 수 있지만 줄일 수는 없다. 다시 줄이는 명령을 내리면 InvalidPartitionsException의 셉션이 발생한다.

분산 시스템에서 이미 분산된 데이터를 줄이는 방법은 매우 복잡하다.

삭제 대상 파티션 을 지정해야할 뿐만 아니라 기존에 저장되어 있던 레코드를 분산하여 저장하는 로직이 필요하기 때문이다.

이 때문에 카프카에서는 파티션을 줄이는 로직은 제공하지 않는다.

만약 피치못할 사정으로 파티션 개수를 줄여야 할 때는 토픽을 새로 만드는편이 좋다.

```java
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic test \\
	--alter --partitions 2
Error while executing topic command :
org.apache.kafka.common.errors.InvalidPartitionsException: Topic currently has 
4 partitions, which is higher than the requested 2.
```

# [kafka-configs.sh](http://kafka-configs.sh)

토픽의 일부 옵션을 설정하기 위해서는 [kafka-configs.sh](http://kafka-configs.sh) 명령어를 사용해야 한다.

--alter과 --add-config 옵션을 사용하여 min.insync.replicas 옵션을 토픽별로 설정할 수 있다.

```java
$ bin/kafka-configs.sh --bootstrap-server my-kafka: 9092 \\
	--alter
	--add-config min.insync. replicas=2 \\
	--topic test

Completed updating config for topic test.

$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic test --describe
Topic: test PartitionCount: 3 ReplicationFactor: 1 Configs:
min.insync. replicas=2, segment .bytes=1073741824
	Topic: test Partition: Leader: 0 Replicas: 0 Isr: 0
	Topic: test Partition: 1 Leader: 0 Replicas: 0 Is: 0
	Topic: test Partition: 2Leader: 0 Replicas: 0 Is: 0
```

브로커에 설정된 각종 기본값은 --broker, --all, -describe 옵션을 사용하여 조회할 수 있다.

```java
$ bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \\
	--broker 0 \\
	--all \\
	--describe
All configs for broker 0 are:
	log.cleaner.min.compaction.lag.ms=0 sensitive=false
synonyms={DEFAULT_CONFIG:log.cleaner.min.compaction.lag.ms=0}
	offsets.topic.num.partitions=50 sensitive=false
synonyms={DEFAULT_CONFIG:offsets.topic.num.partitions=50}
	log.flush.interval.messages=9223372036854775807 sensitive=false
synonyms={DEFAULT_CONFIG:log.flush.interval.messages=9223372036854775807}
```

# [kafka-console-producer.sh](http://kafka-console-producer.sh)

## [kafka-console-producer.sh](http://kafka-console-producer.sh)

hello.kafka 토픽에 데이터를 넣을 수 있는 [kafka-console-producer.sh](http://kafka-console-producer.sh) 명령어를 실행해 보자.

키보드로 문자를 작성하고 엔터 키를 누르면 별다른 응답 없이 메시지 값이 전송된다.

```java
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka: 9092 \\
--topic hello.kafka

>hello
>kafka
>0
>1
>2
>3
>4
>5
>6
```

메시지 키를 가지는 레코드를 전송해 보자. 메시지 키를 가지는 레코드를 전송하기 위해 서는 몇가지 추가 옵션을 작성해야 한다.

key.separator를 선언하지 않으면 기본 설정은 Tab delimiter(wt)이므로 key.separator를 선언하지 않고 메시지를 보내려면 메시지 키를 작성하고 탭키를 누른 뒤 메시지 값을 작 성하고 엔터를 누른다.

여기서는 명시적으로 확인하기 위해 콜론(:)을 구분자로 선언했다.

```java
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \\
	--topic hello.kafka \\
	--property "parse .key=true" \\
	--property "key.separator=:"

>key1: no1
>key2: no2
>key3: no3
```

## 메시지 키와 메시지 값이 포함된 레코드가 파티션에 전송됨

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6b9129aa-6d2f-4688-8613-322736411272/Untitled.png)

메시지 키와 메시지 값을 함께 전송한 레코드는 토픽의 파티션에 저장된다.

메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위(레코드 전송 묶음)로 라운드 로빈으로 전송한다.

메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한개에 할당된다.

이로 인해 메시 지키가 동일한 경우에는 동일한 파티션으로 전송된다

# [kafka-console-consumer.sh](http://kafka-console-consumer.sh)

## [kafka-console-consumer.sh](http://kafka-console-consumer.sh)

hello.kafka 토픽으로 전송한 데이터는 [kafka-console-consumer.sh](http://kafka-console-consumer.sh) 명령어로 확인할 수 있다.

이때 필 수 옵션으로 --bootstrap-server에 카프카 클러스터 정보, -topic에 토픽 이름이 필요하다.

추가로 --from-beginning 옵션을 주면 토픽에 저장된 가장 처음 데이터부터 출력한다.

```java
$ bin/kafka-console-consumer.sh \\
	--bootstrap-server my-kafka: 9092 \\
	--topic hello.kafka --from-beginning

hello kafka
0
1
2
3
```

kafka-console-producer.sh로 보낸 메시지 값이 출력된 것을 확인할 수 있다. 만약 레코드의 메시지 키와 메시지 값을 확인하고 싶다면 --property 옵션을 사용하면 된다.

```java
$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \\
	--topic hello.kafka \\
	--property print.key=true \\
	--property key.separator="-" \\ 
	--from-beginning

key2-no2
key2-no2
key1-no1
null-1
null-2
```

--﻿max-messages 옵션을 사용하면 최대 컨슘 메시지 개수를 설정할 수 있다.

```java
$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 \\
--topic hello.kafka --from-beginning --max-messages 1 
hello
Processed a total of 1 messages
```

—partition 옵션을 사용하면 특정 파티션만 컨슘할 수 있다.

```java
$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka: 9092 \\
	--topic hello.kafka \\
	--partition 2 \\
	--from-beginning 
hello
```

—group 옵션을 사용하면 컨슈머 그룹을 기반으로 Kafka-console-consumer가 동작한다.

컨슈머 그룹이 란 특정 목적을 가진 컨슈머들을 묶음으로 사용하는 것을 뜻한다.

컨슈머 그룹으로 토픽의 레코드를 가져 갈 경우 어느 레코드까지 읽었는지에 대한 데이터가 카프카 브로커에 저장된다.

```java
$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka: 9092 \\
	--topic hello.kafka \\
	--group hello-group
	--from-beginning 
key2-no2
key2-no2
key1-no1
null-1
null-2
```

# [kafka-consumer-groups.sh](http://kafka-consumer-groups.sh)

hello-group 이름의 컨슈머 그룹으로 생성된 컨슈머로 hello.kafka 토픽의 데이터를 가져갔다.

컨슈머 그 룹은 따로 생성하는 명령을 날리지 않고 컨슈머를 동작할 때 컨슈머 그룹이름을 지정하면 새로 생성된다. 생성된 컨슈머 그룹의 리스트는 [kafka-consumer-groups.sh](http://kafka-consumer-groups.sh) 명령어로 확인할 수 있다

```java
$ bin/kafka-consumer-groups. sh \\
	--bootstrap-server my-kafka:9092 \\
	--list hello-group
$ bin/kafka-consumer-groups. sh --bootstrap-server my-kafka:9092 \\
	--group hello-group --describe
```

—describe 옵션을 사용하면 해당 컨슈머 그룹이 어떤 토픽을 대상으로 레코드를 가져갔는지 상태를 확인 할 수 있다.

파티션 번호, 현재까지 가져간 레코드의 오프셋, 파티션 마지막 레코드의 오프셋, 컨슈머 랙, 컨 슈머 ID, 호스트를 알 수 있기 때문에 컨슈머의 상태를 조회할 때 유용하다.

```java
$ bin/kafka-consumer-groups. sh --bootstrap-server my-kafka: 9092 \\
	--group hello-group --describe

Consumer group 'hello-group' has no active members.

GROUP       TOPIC        PARTITION  CURRENT-OFFSET LOG-END-OFFSET LAG
CONSUMER-ID HOST         CLIENT-ID 
hello-group hello.kafka  2          5              5              0
```

## [kafka-consumer-groups.sh](http://kafka-consumer-groups.sh) 오프셋 리셋

```java
$ bin/kafka-consumer-groups. sh \\
	--bootstrap-server my-kafka: 9092 \\
	--group hello-group \\
	--topic hello.kafka \\
	--reset-offsets --to-earliest --execute

$ bin/kafka-console-consumer.sh --bootstrap-server my-kafka: 9092 \\
	--topic hello.kafka \\
	--group hello-group
1
2
3
```

## [kafka-consumer-groups.sh](http://kafka-consumer-groups.sh) 오프셋 리셋 종류

—to-earliest : 가장 처음 오프셋(작은 번호)으로 리셋

—to-latest : 가장 마지막 오프셋(큰 번호)으로 리셋

—to-current : 현 시점 기준 오프셋으로 리셋

—to-datetime (yyYY-MM-DDTHH:mmSS.sss) : 특정 일시로 오프셋 리셋(레코드 타임스탬프 기준)

—to-offset {lono : 특정 오프셋으로 리셋

shift-by (+/- long) : 현재 컨슈머 오프셋에서 앞뒤로 옮겨서 리셋

```java
$ bin/kafka-consumer-groups. sh \\
	--bootstrap-server my-kafka: 9092 \\
	--group hello-group \\
	--topic hello.kafka \\
	--reset-offsets --to-earliest - -execute
```

# 그외 커맨드 라인 툴

## [kafka-producer-perf-test.sh](http://kafka-producer-perf-test.sh)

```java
$ bin/kafka-producer-perf-test.sh \\
	--producer-props bootstrap. servers=my-kafka: 9092 \\
	--topic hello.kafka \\
	--num-records 10 \\
	--throughput 1 \\
	--record-size 100 \\
	--print-metric
7 records sent, 1.3 records/sec (0.00 MB/sec), 28.9 ms avg latency, 184.0 ms max latency.
10 records sent, 1.087666 records/sec (0.00 MB/sec), 20.60 ms avg latency, 184.00 ms 
max latency, 2 ms 50th, 184 m 95th, 184 ms 99th, 184 ms 99.9th.
```

## [kafka-reassign-partitions.sh](http://kafka-reassign-partitions.sh)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0d8c10cf-6ea5-415f-815d-f33eaa61762b/Untitled.png)

kafka-reassign-partitions.sh를 사용하면 리더 파티션과 팔로워 파티션이 위치를 변경할 수 있다.

카프카 브로커에는 auto.leader.rebalance.enable 옵션이 있는데 이 옵션의 기본값은 true로써 클러스터 단위에 서 리더 파티션을 자동 리밸런싱하도록 도와준다.

브로커의 백그라운드 스레드가 일정한 간격으로 리더의 위치를 파악하고 필요시 리더 리밸런싱을 통해 리더의 위치가 알맞게 배분된다.

```java
§ cat partitions. json
{
	"partitions"
	[ {    "topic": "hello.kafka", "partition": 0, "replicas": [ 0 ] } ]
	, "version" : 1
}

$ bin/kafka-reassign-partitions.sh --zookeeper my-kafka:2181 \\
	--reassignment-json-file partitions.json --execute
```

## [kafka-delete-record.sh](http://kafka-delete-record.sh)

```java
$ cat delete.json

{
	"partitions": [
		{
		"topic": "hello kafka", "partition": 0, "offset": 5
		}
	], "version": 1
}

$ bin/kafka-delete-records.sh --bootstrap-server my-kafka: 9092 \\
	--offset-json-file delete. json
Executing records delete operation
Records delete operation completed:
partition: hello.kafka-0  low_watermark: 5
```

## [kafka-dump-log.sh](http://kafka-dump-log.sh)

```java
$ 1s data/hello.kafka-0
00000000000000000000.index  00000000000000000000.timeindex
00000000000000000000.log.   leader-epoch-checkpoint

$ bin/kafka-dump-log.sh \\
	--files data/hello.kafka-0/00000000000000000000. log \\
	--deep-iteration
Dumping data/hello.kafka-0/00000000000000000000. log
Starting offset: 0
base0ffset: 0 lastOffset: 2 count: 3 baseSequence: - 1 lastSequence: - 1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 0 isTransactional: false
isControl: false position: 0 CreateTime: 1642337213446 size: 87 magic: 2
compresscodec: NONE crc: 23690631 isvalid: true
```

# 토픽을 생성하는 두가지 방법

## 토픽을 생성하는 두가지 방법

토픽을 생성하는 상황은 크게 2가지가 있다.

첫 번째는 카프카 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대해 데이터를 요청할 때,

그리고 두 번째는 커맨드 라인 툴로 명시적으로 토픽을 생성하는 것이다.

토픽을 효과적으로 유지보수하기 위해서는 토픽을 명시적으로 생성하는 것을 추천한다.

토픽마다 처리되어야 하는 데이터의 특성이 다르기 때문이다.

토픽을 생성할 때는 데이터 특성에 따라 옵션 을 다르게 설정할 수 있다.

예를 들어, 동시 데이터 처리량이 많아야 하는 토픽의 경우 파티션의 개수를 100으로 설정할 수 있다.

단기간 데이터 처리만 필요한 경우에는 토픽에 들어온 데이터의 보관기간 옵션 을 짧게 설정할 수도 있다.

그러므로 토픽에 들어오는 데이터양과 병렬로 처리되어야 하는 용량을 잘 파악 하여 생성하는 것이 중요하다.

# 카프카 브로커와 CLI 버전을 맞춰야 하는 이유

카프카 브로커로 커맨드 라인 둘 명령을 내릴 때 브로커의 버전과 커맨드 라인 둘 버전을 반드시 맞춰서 사 용하는 것을 권장한다.

브로커의 버전이 업그레이드 됨에 따라 커맨드 라인 툴의 상세 옵션이 달라지기 때 문에 버전 차이로 인해 명령이 정상적으로 실행되지 않을 수 있다.

이번 실습에서는 카프카 2.5.0을 기준으 로 실행하기 때문에 카프카 2.5.0 바이너리 패키지에 들어있는 카프카 커맨드라인 툴을 이용한다.