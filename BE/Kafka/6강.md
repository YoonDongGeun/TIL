# 6강 컨슈머

# 컨슈머 소개

![image-20230507230247559](./6%EA%B0%95.assets/image-20230507230247559.png)

프로듀서가 전송한 데이터는 카프카 브로커에 적재된다.

컨슈머는 적재된 데이터를 사용하기 위해 브로커 로부터 데이터를 가져와서 필요한 처리를 한다.

예를 들어, 마케팅 문자를 고객에게 보내는 기능이 있다면 컨슈머는 토픽으로부터 고객 데이터를 가져와서 문자 발송 처리를 하게 된다.

## 컨슈머 내부 구조

![image-20230507230450270](./6%EA%B0%95.assets/image-20230507230450270.png)

- Fetcher : 리더 파티션으로부터 레코드들을 미리 가져와서 대기.
- poll() : Fetcher에 있는 레코드들을 리턴하는 레코드.
- ConsumerRecords : 처리하고자 하는 레코드들의 모음. 오프셋이 포함되어 있다.

## 컨슈머 그룹

![image-20230511001758411](./6%EA%B0%95.assets/image-20230511001758411.png)

컨슈머 그룹으로 운영하는 방법은 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와주는 카프카의 독특한 방식이다.

컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들 에 할당되어 데이터를 가져갈 수 있다.

컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 때, 1개의 파티션은 최대 1 개의 컨슈머에 할당 가능하다.

그리고 1개 컨슈머는 여러 개의 파티션에 할당될 수 있다.

이러한 특징으로 컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 한다.

## 컨슈머 그룹의 컨슈머가 파티션 개수보다 많을 경우

!![image-20230511002731936](./6%EA%B0%95.assets/image-20230511002731936.png)

만약 4개의 컨슈머로 이루어진 컨슈머 그룹으로 3개의 파티션을 가진 토픽에서 데이터를 가져가기 위해 할당하면 1개의 컨슈머는 파티션을 할당받지 못하고 유휴 상태로 남게 된다.

파티션을 할당받지 못한 컨슈 머는 스레드만 차지하고 실질적인 데이터 처리를 하지 못하므로 애플리케이션 실행에 있어 불필요한 스레 드로 남게 된다.

## 컨슈머 그룹을 활용하는 이유

![image-20230511004737743](./6%EA%B0%95.assets/image-20230511004737743.png)

운영 서버의 주요 리소스인 CPU, 메모리 정보를 수집하는 데이터 파이프라인을 구축한다고 가정해 보자.

실시간 리소스를 시간순으로 확인하기 위해서 데이터를 엘라스틱서치에 저장하고 이와 동시에 대용량 적 재를 위해 하둡에 적재할 것이다.

만약 카프카를 활용한 파이프라인이 아니라면 서버에서 실행되는 리소스 수집 및 전송 에이전트는 수집한 리소스를 엘라스틱서치와 하둡에 적재하기 위해 동기적으로 적재를 요청 할 것이다.

이렇게 동기로 실행되는 에이전트는 엘라스틱서치 또는 하둡 둘 중 하나에 장애가 발생한다면 더는 적재가 불가능할 수 있다.

## 컨슈머 그룹의 컨슈머가 파티션 개수보다 많을 경우

![image-20230511005102415](./6%EA%B0%95.assets/image-20230511005102415.png)

카프카는 이러한 파이프라인을 운영함에 있어 최종 적재되는 저장소의 장애에 유연하게 대응할 수 있도록 각기 다른 저장소에 저장하는 컨슈머를 다른 컨슈머 그룹으로 묶음으로써 각 저장소의 장애에 격리되어 운영할 수 있다.

따라서 엘라스틱서치의 장애로 인해 더는 적재가 되지 못하더라도 하둡으로 데이터를 적재 하는 데에는 문제가 없다.

엘라스틱서치의 장애가 해소되면 엘라스틱서치로 적재하는 컨슈머의 컨슈머 그 룹은 마지막으로 적재 완료한 데이터 이후부터 다시 적재를 수행하여 최종적으로 모두 정상화될 것이다.

# 리밸런싱

![image-20230511005957188](./6%EA%B0%95.assets/image-20230511005957188.png)

컨슈머 그룹으로 이루어진 컨슈머 들 중 일부 컨슈머에 장애가 발생하면, 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생 하지 않은 컨슈머에 소유권이 넘어간다. 이러한 과정을 '리밸런싱(rebalancing)'이 라고 부른다.

리밸런싱은 크게 두 가지 상황에서 일어나는데, 첫 번째는 컨슈머가 추가되는 상황이고 두 번 째는 컨슈머가 제외되는 상황이다.

이슈가 발생한 컨슈머를 컨슈머 그룹에서 제외하여 모든 파티션이 지속 적으로 데이터를 처리할 수 있도록 가용성을 높여준다.

리밸런싱은 컨슈머가 데이터를 처리하는 도중에 언 제든지 발생할 수 있으므로 데이터 처리 중 발생한 리밸런싱에 대응하는 코드를 작성해야 한다.

# 커밋

![image-20230511012615625](./6%EA%B0%95.assets/image-20230511012615625.png)

컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 커밋(commit)을 통해 기록한다.

특정 토픽 의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지 카프카 브로커 내부에서 사용되는 내부 토픽 (consumer_offsets)에 기록된다.

컨슈머 동작 이슈가 발생하여 consumer_offsets 토픽에 어느 레 코드까지 읽어갔는지 오프셋 커밋이 기록되지 못했다면 데이터 처리의 중복이 발생할 수 있다.

그러므로 데이터 처리의 중복이 발생하지 않게 하기 위해 서는 컨슈머 애플리케이션이 오프셋 커밋을 정상적으로 처리했는지 검증해야만 한다.

# 어사이너

컨슈머와 파티션 할당 정책은 컨슈머의 어싸이너에 의해 결정된다. 카프카에서는 RangeAssignor, RoundRobinAssignor, StickyAssignor를 제공한다.

카프카 2.5.0는 RangeAssignor가 기본값으로 설정 된다.

- RangeAssignor : 각 토픽에서 파티션을 숫자로 정렬, 컨슈머를 사전 순서로 정렬하여 할당.
- RoundRobinAssignor : 모든 파티션을 컨슈머에서 번갈아가면서 할당.
- StickyAssignor : 최대한 파티션을 균등하게 배분하면서 할당.

# 컨슈머 주요 옵션 소개

## 컨슈머 주요 옵션(필수 옵션)

- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접 속하는 데에 이슈가 없도록 설정 가능하다.
- key.deserializer: 레코드의 메시지 키를 역직렬화하는 클래스를 지정한다.
- value.deserializer: 레코드의 메시지 값을 역직렬화하는 클래스를 지정한다.

## 컨슈머 주요 옵션(선택 옵션)

- [group.id](http://group.id): 컨슈머 그룹 아이디를 지정한다. subscribe() 메서드로 토픽을 구독하여 사용할 때는 이 옵션을 필수로 넣어야 한다. 기본값은 null이다.
- auto.offset.reset: 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프 셋부터 읽을지 선택하는 옵션이다. 이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다. 기본값은 Iatestol 다.
- enable. auto.commit: 자동 커밋으로 할지 수동 커밋으로 할지 선택한다. 기본값은 true 이다.
- [auto.commit.interval.ms](http://auto.commit.interval.ms): 자동 커밋일 경우 오프셋 커밋 간 격을 지정한다. 기본값은 5000(5초)이다.
- max.poll.records: poll ( ) 메서드를 통해 반환되는 레코드 개수를 지정한다. 기본값은 500 이다.
- [session.timeout.ms](http://session.timeout.ms): 컨슈머가 브로커와 연결이 끊기는 최대 시간이다. 기본값은 10000(10초)이다.
- [hearbeat.interval.ms](http://hearbeat.interval.ms): 하트비트를 전송하는 시간 간격이다. 기본값은 3000(3초)이다.
- max,[pollinterval.ms](http://pollinterval.ms): poll( ) 메서드를 호출하는 간격의 최대 시간. 기본값은 300000(5분)이다.
- isolation. level: 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용한다.

# auto.offset.reset

컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택하 는 옵션이다. 이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다. 이 옵션은 latest, earliest, none 중 1 개를 설정할 수 있다.

- latest: 설정하면 가장 높은(가장 최근에 넣은) 오프셋부터 읽기 시작한다.
- earliest: 설정하면 가장 낮은(가장 오래전에 넣은) 오프셋부터 읽기 시작한다.
- none: 설정하면 컨슈머 그룹이 커밋한 기록이 있는지 찾아본다. 만약 커밋 기록이 없으면 오류를 반환하 고, 커밋 기록이 있다면 기존 커밋 기록 이후 오프셋부터 읽기 시작한다. 기본값은 Iatest이다.

# 컨슈머 애플리케이션 개발하기

```java
public class SimpleConsumer {
	private final static Logger logger = LoggerFactory. getLogger (SimpleConsumer .class);
	private final static String TOPIC_NAME = "test";
	private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";
	private final static String GROUP_ID ="test-group";

	public static void main(String[] args) {
		Properties configs = new Properties();
		configs-put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,BOOTSTRAP_SERVERS);
		configs.put(ConsumerConfig.GROUP_ID_CONFIG,GROUP_ID);
		configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class-getName());
		configs.pt (ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());
		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
		consumer.subscribe(Arrays.asList(TOPIC_NAME));
	}
}
public class SimpleConsumer {
	private final static Logger logger = LoggerFactory-getLogger (SimpleConsumer .class);
	private final static String TOPIC_NAME = "test";
	private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";
	private final static String GROUP_ID = "test-group"
	public static void main(String[] args) {
		while (true) {
			ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1)) ;
			for (ConsumerRecord String, String> record : records) {
			logger.info("record:()", record);
		}
	}
}
public class SimpleConsumer {
	private final static Logger logger = LoggerFactory-getLogger (SimpleConsumer .class);
	private final static String TOPIC_NAME = "test";
	private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";
	private final static String GROUP_ID = "test-group"
	public static void main(String[] args) {
		while (true) {
			ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1)) ;
			for (ConsumerRecord String, String> record : records) {
			logger.info("record:()", record);
		}
	}
}
```

# 수동 커밋 컨슈머 애플리케이션

## 동기 오프셋 커밋 컨슈머

poll() 메서드가 호출된 이후에 commitSync() 메서드를 호출하여 오프셋 커밋을 명시적으로 수행할 수 있다.

commitSync()는 poll() 메서드로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋한다.

동기 오프 셋 커밋을 사용할 경우에는 poll() 메서드로 받은 모든 레코드의 처리가 끝난 이후 commitSync() 메서드 를 호출해야 한다.

```java
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
consumer.subscribe(Arrays.asList(TOPIC_NAME)) ;

while (true) {
	ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1)) ;
	for (ConsumerRecord<String, String> record : records) {
		logger. info("record: {}", record);
	}
	consumer.commitSync( );
}
```

## 동기 오프셋 커밋(레코드 단위) 컨슈머

```java
KafkaConsumer<String, String> consumer = new KafkaConsumer<> (configs) ;
consumer.subscribe(Arrays. asList (TOPIC_NAME));
while (true) {
	ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds (1)) ;
	Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<> () ;
	for (ConsumerRecord<String, String> record : records) {
		logger.info("record: {}", record);
		currentOffset.put(
			new TopicPartition(record.topic() , record. partition ()), 
			new OffsetAndMetadata(record.offset() + 1, null));
		consumer. commitSync (current0ffset) ;
	}
}
```

## 비동기 오프셋 커밋 컨슈머

동기 오프셋 커밋을 사용할 경우 커밋 응답을 기다리는 동안 데이터 처리가 일시적으로 중단 되기 때문에 더 많은 데이터를 처리하기 위해서 비동기 오프셋 커밋을 사용할 수 있다.

비동기 오프셋 커밋은 commitAsync() 메서드를 호출하여 사용할 수 있다.

```java
KafkaConsumer<String, String> consumer = new KafkaConsumer<> (configs);
consumer.subscribe(Arrays.asList (TOPIC_NAME)) ;

while (true) {
	ConsumerRecords<String, String> records = consumer .poll(Duration.ofSeconds(1)) ;
	for(ConsumerRecord<String, String> record : records) {
		logger.info("record: {}", record);
	}
consumer.commitAsync();
}
```

## 비동기 오프셋 커밋 콜백

```java
while (true) {
	ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1)) ;
	for (ConsumerRecord<String, String> record : records) {
		logger. info("record: {)", record);
	}
	consumer.commitAsync(new OffsetCommitCallback() {
		public void onComplete (Map TopicPartition, OffsetAndMetadata> offsets, Exception e) {
			if (e != null)
				System.err.println("Commit failed");
			else
				System.out.printIn("Commit succeeded");
			if (e != null)
				logger. error("Commit failed for offsets {}", offsets, e);
		}
	});
}
```

# 리밸런스 리스너를 가진 컨슈머 애플리케이션

리밸런스 발생을 감지하기 위해 카프카 라이브러리는 ConsumerRebalanceListener 인터페이스를 지원 한다. ConsumerRebalanceListener 인터페이스로 구현된 클래스는 onPartitionAssigned() 메서드 와 onPartitionRevoked() 메서드로 이루어져 있다.

- onPartitionAssgined(): 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되는 메서드이다.
- onPartitionRevoked(): 리밸런스가 시작되기 직전 에 호출되는 메서드이다. 마지막으로 처리한 레코드 를 기준으로 커밋을 하기 위해서는 리밸런스가 시작하기 직전에 커밋을 하면 되므로 onPartitionRevoked() 메서드에 커밋을 구현하여 처리할 수 있다.

```java
public class RebalanceListener implements ConsumerRebalanceListener {
	private final static Logger logger = LoggerFactory .getLogger(RebalanceListener.class);
	public void onPartitionsAssigned(Collection‹TopicPartition> partitions) {
		logger warn("Partitions are assigned");
	}
	public void onPartitionsRevoked(Collection<Topicartition> partitions) {
		logger .warn("Partitions are revoked");
	}
}
```

# 파티션 할당 컨슈머 애플리케이션

```java
private final static int PARTITION_NUMBER = 0;
private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

public static void main(String[] args) {
	KafkaConsumer<String, String> consumer = new KafkaConsumer<> (configs) ;
	consumer .assign(Collections.singleton(new Topicartition(TOPIC_NAME, PARTITION_NUMBER)))
	while (true) {
		Consumerecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
		for (ConsumerRecord<String, String> record : records) {
			logger . info("record: ()", record);
		}
	}
}
```

# 컨슈머 애플리케이션의 안전한 종료

컨슈머 애플리케이션은 안전하게 종료되어야 한다.

정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할때까지 컨슈머 그룹에 남게 된다.

컨슈머를 안전하게 종료하기 위해 KafkaConsumer 클래스는 wakeup() 메서드를 지원한다.

wakeup() 메서드를 실행하여 KafkaConsumer 인스턴스를 안전하게 종료 할 수 있다.

wakeup() 메서드가 실행된 이후 poll() 메서드가 호출되면 WakeupException 예외가 발생한다.

Wakeup Exception 예외를 받은 뒤에는 데이터 처리를 위해 사용한 자원들을 해제하면 된다.